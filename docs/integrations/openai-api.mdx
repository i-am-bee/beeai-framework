---
title: "OpenAI API"
icon: "server"
---

The [OpenAI API](https://platform.openai.com/docs/quickstart) provides a simple interface to state-of-the-art AI models for text generation, natural language processing, computer vision, and more.

---

<Heading level={2} id="server">OpenAI Server</Heading>

OpenAIServer allows you to expose your agents and LLMs to external systems that support the Chat completion or Responses API.

Key benefits
- Fast setup with minimal configuration
- Support for [Chat Completion API](https://platform.openai.com/docs/api-reference/chat) and [Responses API](https://platform.openai.com/docs/api-reference/responses)
- Register multiple agents and LLMs on a single server
- Custom server settings

<CodeGroup>

	{/* <!-- embedme python/examples/serve/openai_server.py --> */}
	```py Python
	from beeai_framework.adapters.openai.serve.server import OpenAIAPIType, OpenAIServer, OpenAIServerConfig
	from beeai_framework.agents.requirement import RequirementAgent
	from beeai_framework.backend import ChatModel
	from beeai_framework.memory import UnconstrainedMemory
	from beeai_framework.tools.weather import OpenMeteoTool
	
	
	def main() -> None:
	    llm = ChatModel.from_name("ollama:granite4:micro")
	    agent = RequirementAgent(
	        llm=llm,
	        tools=[OpenMeteoTool()],
	        memory=UnconstrainedMemory(),
	    )
	
	    server = OpenAIServer(
	        config=OpenAIServerConfig(
	            port=9998,
	            api=OpenAIAPIType.RESPONSES,
	        )
	    )
	    server.register(agent, name="agent")
	    server.register(llm)
	    server.serve()
	
	
	if __name__ == "__main__":
	    main()
	
	```

	```ts TypeScript
	 // coming soon
	```

</CodeGroup>

You can easily call the exposed entities via cURL.

<CodeGroup>

	```sh Responses API
	curl --location 'http://0.0.0.0:9998/responses' \
	--header 'Content-Type: application/json' \
	--data '{
		"model": "agent",
		"conversation": "123",
		"stream": false,
		"input": "Hello, how are you?"
	}'
	```

	```sh Chat Completion API
	curl --location 'http://0.0.0.0:9998/chat/completions' \
	--header 'Content-Type: application/json' \
	--data '{
	    "model": "agent",
	    "stream": false,
	    "messages": [
	        {
	            "role": "user",
	            "content": "Hello, how are you?"
	        }
	    ]
	}'
	```

</CodeGroup>
