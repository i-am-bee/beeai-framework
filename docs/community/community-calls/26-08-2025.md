# BeeAI Framework Community Update

## August 26, 2025

---

## üõ†Ô∏è Major Improvements

### General
- **Parallel Tool Calls Support** - Execute multiple tools simultaneously for better performance
- **Backend Streaming** - Better text and tool calls streaming processing and error handling
- **Serve module** - MCP, BeeAI platform and A2A are now compatible with the latest versions
- **OpenTelemetry** - Our OpenTelemetry integration has been reworked from scratch, is more reliable and supports all modules in the framework (see our Observability docs page). 

### RAG Module Expansion
- **Vector Store Tool** - Semantic search capabilities for any agent
- **Document Loader** - Support for multiple document formats
- **Text Splitter Backend** - Intelligent document chunking strategies
- **Dynamic Loading** - Load RAG components using configuration strings

---

## üîß Quality & Reliability Updates

### LLMs, Agents and Tools
- Fixed streaming chunk processing for better real-time responses
- Enhanced tool choice validation and error messages
- Add Google Gemini adapter
- Add cost tracking (part of the ChatModelOutput) and telemetry
- Handle duplicated rules in RequirementAgent
- Improve the performance of the Handoff tool
- Enhanced MCP client session cleanup

### Developer Experience
- New snapshot testing with Syrupy for better test reliability

---

## üó∫Ô∏è What's Coming Next

**Priorities:**
1. **Runnables Migration** - Major refactoring to the agents so that are easier to use, compose and build.
2. **Workflows V2** - Introducing a decorator-based, fully declarative approach to workflows
3. **Loader Module** - Configure agents with YAML files for easier deployment
4. **Simplified Serving** - Streamlined platform deployment experience
5. **Agent Consolidation** - Single unified `Agent` class to replace multiple agent types

---

## üí¨ Community Input Needed

- **Workflows V2** - Let us know your thoughts on [the proposal](https://github.com/i-am-bee/beeai-framework/discussions/1005)!
- **Chat Completion Serve Integration** Let us know if you'd like to see the [integration](https://github.com/i-am-bee/beeai-framework/discussions/1008) in the serve module.
- **Test the new Runnable interface foundation** - Help us design the agent/workflow integration

**Join the discussion:** [discord.gg/NradeA6ZNF](https://discord.gg/NradeA6ZNF)

---

## üôè Community Recognition

### Core Maintainers
Thank you to our dedicated maintainers for their contributions this period:
- **[@araujof](https://github.com/araujof)** - Implemented the foundational Runnable interface (#982)
- **[@Tomas2D](https://github.com/Tomas2D)** - Enhanced serialization (#1001), parallel tool calls (#986), streaming improvements (#973), schema transformations (#996), and multiple bug fixes
- **[@xjacka](https://github.com/xjacka)** - Built memory manager for serving (#983), A2A upgrades (#951), context-based memory (#975), and Watsonx integration improvements (#948)
- **[@antonpibm](https://github.com/antonpibm)** - Developed RAG module: vector store tool (#991), document loader (#962), text splitter (#974), dynamic processors (#979), and comprehensive documentation (#952)

### External Contributors
Special thanks to our community contributors this period:
- **[@richardesp](https://github.com/richardesp)** - Cost tracking and LiteLLM response cost integration (#926)
- **[@nforro](https://github.com/nforro)** - Google Gemini backend implementation (#939)
- **[@Niamorine](https://github.com/Niamorine)** - Fixed critical MCP tool error (#922)

### Linux Foundation AI & Data
BeeAI Framework is proud to be part of the [Linux Foundation AI & Data program](https://lfaidata.foundation/projects/), fostering open, collaborative, and community-driven development.

---

## üôè Thank You

The BeeAI Framework is community-driven - your feedback shapes our roadmap!

Questions? Let's discuss!
- **Discord Community**: [discord.gg/NradeA6ZNF](https://discord.gg/NradeA6ZNF)
- **GitHub Discussions**: Share ideas and ask questions
