---
title: "Serve"
description: ""
icon: "truck"
---

The `Serve` module enables developers to expose components built with the BeeAI Framework through a server to external clients.
Out of the box, we provide implementations for protocols such as A2A and MCP, allowing you to quickly serve existing functionalities.
You can also create your own custom adapter if needed.

<Note>
Location within the framework: [beeai_framework/serve](https://github.com/i-am-bee/beeai-framework/blob/main/python/beeai_framework/serve).
</Note>

## Supported Providers

The following table lists the currently supported providers:

| Name                                                  | Dependency                                   | Location                    |
|:-----------------------------------------------------|:--------------------------------------------|:---------------------------|
| [A2A](https://a2a-protocol.org/)       | `beeai_framework.adapters.a2a.serve`         | `beeai-platform[a2a]`       |
| [BeeAI Platform](https://beeai.dev/)                | `beeai_framework.adapters.beeai_platform.serve` | `beeai-platform[beeai-platform]` |
| [MCP](https://modelcontextprotocol.io/) | `beeai_framework.adapters.mcp.serve`         | `beeai-platform[mcp]`       |

<Note>
For more details, see the [Integrations page](/integrations).
</Note>

## Usage

{/* <!-- embedme python/examples/serve/a2a_server.py --> */}
```python
from beeai_framework.adapters.a2a import A2AServer, A2AServerConfig
from beeai_framework.agents.requirement import RequirementAgent
from beeai_framework.backend import ChatModel
from beeai_framework.memory import UnconstrainedMemory
from beeai_framework.serve.utils import LRUMemoryManager
from beeai_framework.tools.search.duckduckgo import DuckDuckGoSearchTool
from beeai_framework.tools.weather import OpenMeteoTool


def main() -> None:
    llm = ChatModel.from_name("ollama:granite4:micro")
    agent = RequirementAgent(
        llm=llm,
        tools=[DuckDuckGoSearchTool(), OpenMeteoTool()],
        memory=UnconstrainedMemory(),
    )

    # Register the agent with the A2A server and run the HTTP server
    # For the ToolCallingAgent, we don't need to specify ACPAgent factory method
    # because it is already registered in the A2AServer
    # we use LRU memory manager to keep limited amount of sessions in the memory
    A2AServer(
        config=A2AServerConfig(port=9999, protocol="jsonrpc"), memory_manager=LRUMemoryManager(maxsize=100)
    ).register(agent, send_trajectory=True).serve()


if __name__ == "__main__":
    main()

```

## Extending Functionality

By default, each provider supports registration of a limited set of modules (agents, tools, templates, etc.).
You can extend this functionality by registering a custom factory using `Server.register_factory` method.
